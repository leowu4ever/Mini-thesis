\chapter{Summary and Future Research Plan}
\section{Summary}
So far, after a large number of relevant research literatures have been evaluated and the analytical methods used in the relevant studies have been considered, this study decided to use the spectrogram generated by the respiratory sound signal to estimate the frequency of breathing with CNN, to determine the stage of breathing and The depth of breathing. The work currently done includes the development of ethics proposal, the collection and labelling of test data, and the use of Colaboratory for prototyping of different signal processing, dataset generation and classifier processes. The results of the tests show that the data sets generated by manual annotation are sufficient for training of classification, and the various methods used in the signal processing flow are very effective. The signal processing flow preserves the respiratory-related frequency components while removing unwanted frequency components. Finally, through the transfer learning, using the Resent model provided by Fastai to distinguish whether a sound is an exhalation sound or an inhalation sound. The performance of the classifier trained with the test data achieved over 50\% accuracy without any fine tuning. After being able to judge the breathing phase, the frequency of breathing can be estimated accordingly.
\section{Future research plan}
Future research work focuses on preparing data, comparing other combinations of signal processing methods, and various machine learning, such as support vecter machine. The details of each of the focuses is discussed in the follow sections.
\subsection{Dataset generation}

labelling where the in/out starts by aligning the audio signal with the reference signal

Conventional data augmentation includes scaling, stratching, cropping and etc. However, the data augmentation for audio-generated spectrogram image uses completely different mechanisims.

\subsection{Signal pre-processing}
segmentation size


Hilbert huang transform

explore different combination of signal processing approach

\subsection{Feature extraction}
Excepting  

ddiscriminating the respiratory phase 

LPC feature

perceptual feature (Per)

cepstral (Cep) features

perceptual and cepstral (PerCep) features 

enhanced hybrid perceptual and cepstral (PerCepD) features.

spectural bandwidth
spectral rolloff
spectral centriod
spectral contrast
spectral flatness
spectral mfcc
spectral mfcc delta
spectral mfcc delta of delta

\subsection{Data augmentation}
The purpose of data augmentation is to increase the variety of the dataset especially when the dataset is small. Unlikely traditional image augmentation, cropping, zooming and scaling do not work well and even creating data with misleading labels. 

Data augmentation has not yet been implemented in this work. However, some research has been done in exploring approaches creating additional data based on existing dataset.\cite{Cho2017DeepBreathSettings} \cite{Schluter2015ExploringNetworks}

According to the study undertaken by Schluter and Grill, the most effective augmentation approach is pitch shifting. By also combining the time stretching and random frequency filtering, it could reduced the error signifcantly between 10 and 30\%.\cite{Schluter2015ExploringNetworks}

\subsection{Classification}
continue to use CNN when formal data is collected
experiment other machine learning for performance comparasion

SVN

random forest and support vector machine

information gain
combination of different features


\subsection{Mobile application development}

The model created and trained with Fastai will then be exported to Core ML which is a machine learning suite provided by Apple.

To transfer the complete solution to mobile platform where the computation resource is limited. 

CNN image grey scale
CNN levels

High sampling rate results in large audio files which requires a lot of computing resource 


It is necessary to explore 

aim to provide respiration-related information in real-time. therefore data size and computational complexity and time taken should be taken into account.

It might require some optimisation for fulfil the requirements. either reduce the size of the data used to represent or reduce the number of layers

also try embedded model (weighted model)